{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border:1px solid black; padding:20px 20px;text-align: justify;text-justify: inter-word\">\n",
    "    <strong>Exercise Session 3 - Artificial neural networks<br/> Autumn 2021 <br/> Duration : 4 hours (2 in session + 2 at home)</strong><br/><br/>\n",
    "    <span style=\"text-decoration:underline;font-weight:bold;\">How to use this notebook?</span><br/>\n",
    "    This notebook is made of text cells and code cells. The code cells have to be <strong>executed</strong> to see the result of the program. To execute a cell, simply select it and click on the \"play\" button (<span style=\"font: bold 12px/30px Arial, serif;\">&#9658;</span>) in the tool bar just above the notebook, or type <code>shift + enter</code>. It is important to execute the code cells in their order of appearance in the notebook.<br/>\n",
    "You can make use of the table of contents to navigate easily between sections.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"justify;text-justify: inter-word\">\n",
    "So that you may familiarise with the notebooks and the basic python syntax, the exercises are provided in notebook form and whenever there are any calculations to be made, we encourage you to do them by code. Also, if you want to take notes, we encourage you to use the markdown or Raw NBConvert cells. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-Goals\" data-toc-modified-id=\"Learning-Goals-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Learning Goals</a></span></li><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Requirements</a></span></li><li><span><a href=\"#Activity-1---Artificial-Neural-Networks\" data-toc-modified-id=\"Activity-1---Artificial-Neural-Networks-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Activity 1 - Artificial Neural Networks</a></span></li><li><span><a href=\"#ANN-for-Robot-Control\" data-toc-modified-id=\"ANN-for-Robot-Control-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>ANN for Robot Control</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reactive-Control\" data-toc-modified-id=\"Reactive-Control-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Reactive Control</a></span><ul class=\"toc-item\"><li><span><a href=\"#ASEBA-Implementation\" data-toc-modified-id=\"ASEBA-Implementation-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>ASEBA Implementation</a></span></li><li><span><a href=\"#Python-vs.-ASEBA-Comparison\" data-toc-modified-id=\"Python-vs.-ASEBA-Comparison-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Python vs. ASEBA Comparison</a></span></li></ul></li><li><span><a href=\"#Memory\" data-toc-modified-id=\"Memory-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Memory</a></span></li><li><span><a href=\"#Hebbian-Rule\" data-toc-modified-id=\"Hebbian-Rule-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Hebbian Rule</a></span><ul class=\"toc-item\"><li><span><a href=\"#On-paper\" data-toc-modified-id=\"On-paper-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>On paper</a></span></li><li><span><a href=\"#Implementation\" data-toc-modified-id=\"Implementation-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Implementation</a></span></li></ul></li></ul></li><li><span><a href=\"#Architectures\" data-toc-modified-id=\"Architectures-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Architectures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Activity-5-:-Finite-State-Machines\" data-toc-modified-id=\"Activity-5-:-Finite-State-Machines-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Activity 5 : Finite State Machines</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Learning Goals\n",
    "\n",
    "\n",
    "- Use of artificial neural networks (ANN) for reactive control, based on fixed and learned connections.\n",
    "\n",
    "\n",
    "- Getting a better intuitive idea of what a neuron is able to do.\n",
    "\n",
    "\n",
    "- Applying a neural network and a learning rule to control a robot.\n",
    "\n",
    "\n",
    "\n",
    "***Note that the ANN related coding exercises will be conducted with ASEBA studio to make use of the events on the Thymio, notably those in relation to the button presses. Generally speaking, coding on the Thymio directly leads to more efficient programs than those on the Jupyter notebook which rely heavily on the communication and tends to involve delays.***\n",
    "\n",
    "Additionally : \n",
    "\n",
    "* Implement a simple reactive architecture and understand their potentials and limitations. \n",
    "\n",
    "\n",
    "# Requirements\n",
    "\n",
    "- Thymio\n",
    "\n",
    "- The G printed in A3 format (path-transitions.pdf)\n",
    "\n",
    "![path-transitions](images/path-transitions.png)\n",
    "\n",
    "\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tdmclient in c:\\users\\guill\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.1.11)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000023D4E80E820>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tdmclient/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000023D4E80EA30>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tdmclient/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000023D4E80EBE0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tdmclient/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000023D4E80ED90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tdmclient/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000023D4E80EF40>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tdmclient/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: zeroconf in c:\\users\\guill\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tdmclient) (0.36.13)\n",
      "Requirement already satisfied: ifaddr>=0.1.7 in c:\\users\\guill\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from zeroconf->tdmclient) (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tdmclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 1 - Artificial Neural Networks\n",
    "\n",
    "It is important to understand what type of function a single neuron can generate, and when we\n",
    "need several layers.\n",
    "This first exercice can be done on paper. Consider the neuron illustrated in the Figure below. The figure shows an artificial neuron with three inputs, x1, x2, and 1, and one output y. The\n",
    "purpose of the input 1 is not to be connected to an external input, but instead to introduce\n",
    "a constant value of 1. The input values of x1 and x2 are assumed to be 0 or 1. As output\n",
    "function f we consider the step function:\n",
    "\n",
    "\n",
    "\\begin{array}{ll}\n",
    "f(x) = 0 & \\;\\;\\;\\textrm{if} \\;\\; x < 0\\\\\n",
    "f(x) = 1 & \\;\\;\\;\\textrm{if} \\;\\; x \\geq 0\\,.\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/single_neuron.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "**1. Assign weights w0, w1, w2 so that y is greater than 0 if and only if the values of x1 or x2 or both are 1. This implements the logic gate for or.**\n",
    "\n",
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "or : since the output function f is a step function, the weighted sum must be < 0 if both x1\n",
    "and x2 are 0, and ≥ 0 if at least one of them is 1. There are many solutions. Here is one:\n",
    "w0 = −1 and w1 = w2 = 2.\n",
    "\n",
    "</blockquote>\n",
    "</span>\n",
    "\n",
    "**2. Assign weights w0, w1, w2 so that y is greater than zero if and only if the values of both x1 and x2 are 1. This implements the logic gate for and.**\n",
    "\n",
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "and: the weighted sum must be < 0 if at least one of x1 or x2 is 0, and ≥ 0 if both are 1.\n",
    "Here is a solution: w0 = −3 and w1 = w2 = 2.\n",
    "\n",
    "</blockquote>\n",
    "</span>\n",
    "\n",
    "**3. Can you assign weights w0, w1, w2 so that you implement the logic gate for xor? Why?**\n",
    "\n",
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "    \n",
    "xor : there is no solution. The weighted sum with offset maps the inputs to a height on a plane\n",
    "y(x1, x2) = w0 + w1x1 + w2x2 in space (x1, x2, y). There is no plane such that y(0, 0) < 0 and\n",
    "y(1, 1) < 0 while y(0, 1) ≥ 0 and y(1, 0) ≥ 0. To prove it, consider the following inequalities:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{array}{rcl}\n",
    "w_0 & < & 0 \\\\\n",
    "w_0+w_1 & \\ge & 0 \\\\\n",
    "w_0+w_2 & \\ge & 0 \\\\\n",
    "w_0+w_1+w_2 & < & 0\n",
    "\\end{array}.\n",
    "\n",
    "\n",
    "\n",
    "Adding the 1st and 4th ones, and 2nd and 3rd ones, gives\n",
    "\n",
    "\\begin{array}{rcl}\n",
    "2w_0+w_1+w_2 & < & 0 \\\\\n",
    "2w_0+w_1+w_2 & \\ge & 0\n",
    "\\end{array}\n",
    "\n",
    "which cannot be satisfied simultaneously. \n",
    "\n",
    "More intuitively, a one layered neural network can only model linearly separable functions. With a XOR there is no way to linearly separate the 1 and the 0 outputs. You can do the graph to check yourself.\n",
    "\n",
    "</blockquote>\n",
    "</span>\n",
    "\n",
    "------\n",
    "\n",
    "Consider the two-layer ANN shown in the Figure below. For this exercise, assume that the weights wi are in\n",
    "the range −1.0 to 1.0 ; and the function f is defined as f(x) = x for −1 ≤ x ≤ 1, and saturates the\n",
    "input to −1 or 1 outside this range. We fix the following weights:\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/double_layer_neuron.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "\\begin{array}{c}\n",
    " w_{11}=1,\\, w_{12}=0.5,\\, w_{21}=1,\\, w_{22}=-1\\,. \n",
    "\\end{array}\n",
    "\n",
    "\n",
    "**Compute the values and draw graphs of the outputs of the neurons of the hidden layer (the two\n",
    "left neurons) and the output layer (the right neuron) as function of an input x in the range −2.0\n",
    "to 2.0. Can you obtain the same output from an ANN with only one layer?**\n",
    "\n",
    "\n",
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "The figure below shows the output of hidden neurons and output neuron. The same output could not be\n",
    "obtained without hidden layer if the activation function is the same (obviously a different activation\n",
    "function could be selected to obtained any desired output since we have a single input).\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/ex1_sol.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "</blockquote>\n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for Robot Control\n",
    "\n",
    "Consider an ANN making a full connection between sensors and motors with a single layer of two\n",
    "neurons, as illustrated in the Figure below. The figure illutrates the ANN for the control of the obstacle avoidance of a robot. Implement the neural network in code so that the robot can avoid obstacles. Note that you will need to calculate appropriate weights $w_{il}$ and $w_{ir}$ for $i \\in [1, 7]$ which correspond to the number of available proximity sensors. To set the initial weights you can use your intuition (later in this jupyter notebook you will have the chance to correct the weights by reinforcing the correct decisions of the robot).\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](Images/ANN_robot_control.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "## Reactive Control\n",
    "\n",
    "Implement on Thymio, using the ASEBA language, an ANN with the structure presented above and taking as input all seven proximity sensors, as given in algorithm 2.1 \n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](Images/ANN_algorithm.png)\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASEBA Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Thymio-II program: ANN for obstacle avoidance without memory\n",
    "    # Copyright 2017 by Francesco Mondada and Moti Ben-Ari\n",
    "    # CreativeCommons BY-SA 3.0\n",
    "\n",
    "    # This program implements obstacle avoidance using an ANN\n",
    "    # The inputs x1-7 are taken from the proximity sensors and scaled\n",
    "    # The inputs are multiplied by the weights \n",
    "    #   and used to set the motor powers\n",
    "    # The center button starts and stops the robot\n",
    "\n",
    "    # Weights of neuron inputs\n",
    "    var w_l[7] = [40,20,-20,-20,-40,30,-10]  # connection to left motor\n",
    "    var w_r[7] = [-40,-20,-20,20,40,-10,30]  # connection to right motor\n",
    "\n",
    "    # Neuron inputs and outputs\n",
    "    var x[7]\n",
    "    var y[2]\n",
    "\n",
    "    #iterations\n",
    "    var i\n",
    "\n",
    "    # Scale factors for sensors and constant factor\n",
    "    var sensor_scale   = 200\n",
    "    var constant_scale =  20\n",
    "\n",
    "    # State for start and stop\n",
    "    var state = 1\n",
    "\n",
    "    timer.period[0] = 100    # Milliseconds\n",
    "\n",
    "    # Toggle start and stop with center button\n",
    "    onevent button.center\n",
    "      when button.center == 0 do\n",
    "        if state == 0 then\n",
    "            state = 1\n",
    "        else\n",
    "          state = 0\n",
    "          motor.left.target  = 0\n",
    "          motor.right.target = 0\n",
    "        end\n",
    "      end\n",
    "\n",
    "    # Activiate neurons periodically\n",
    "    onevent timer0\n",
    "      # Do nothing if stopped\n",
    "      if state == 0 then return end\n",
    "\n",
    "      # Get and scale inputs\n",
    "      for i in 0:6 do\n",
    "        x[i] = prox.horizontal[i]/sensor_scale\n",
    "      end\n",
    "\n",
    "      # Compute outputs of neurons and set motor powers\n",
    "\n",
    "      y[0] = 0\n",
    "      y[1] = 0\n",
    "\n",
    "      for i in 0:6 do\n",
    "          y[0] += x[i]*w_l[i]\n",
    "          y[1] += x[i]*w_r[i]\n",
    "      end\n",
    "      motor.left.target  = y[0]\n",
    "      motor.right.target = y[1]\n",
    "\n",
    "</blockquote>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the following implementation uses python, but your code will be *transpiled* in ASEBA. So, in the end, it will be equivalent to the ASEBA code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:37:40.106545Z",
     "start_time": "2021-09-29T14:37:37.390170Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you did not install tdmclient, try \"!pip install tdmclient\", \n",
    "# or have a look at the tutorial \"Control your Thymio in Python\"\n",
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T18:25:33.558579Z",
     "start_time": "2021-10-03T18:25:33.528881Z"
    }
   },
   "outputs": [],
   "source": [
    "%%run_python #%%transpile_to_aseba # Change to see the code generated in Aseba\n",
    "\n",
    "# This program implements obstacle avoidance using an ANN\n",
    "# The inputs x1-7 are taken from the proximity sensors and scaled\n",
    "# The inputs are multiplied by the weights \n",
    "#   and used to set the motor powers\n",
    "# The center button starts and stops the robot\n",
    "\n",
    "# State for start and stop, why is this instruction here? (hint: look at the aseba transpile code)\n",
    "state = 1\n",
    "\n",
    "def see_nothing_front(sensor_array, threshold)\n",
    "    for i in range(len(size_sensor_array)):\n",
    "        tot = tot + array[i]\n",
    "    if tot <= treshold :\n",
    "        return true else false \n",
    "\n",
    "@onevent\n",
    "def button_center():\n",
    "    global state\n",
    "    if button_center == 1:\n",
    "        state = 1 if state==0 else 0\n",
    "\n",
    "@onevent\n",
    "def prox():\n",
    "    global prox_horizontal, motor_left_target, motor_right_target, button_center, state\n",
    "\n",
    "    w_l = [40,  20, -20, -20, -40,  30, -10]\n",
    "    w_r = [-40, -20, -20,  20,  40, -10,  30]\n",
    "\n",
    "    # Scale factors for sensors and constant factor\n",
    "    sensor_scale = 200\n",
    "    constant_scale = 20\n",
    "    \n",
    "    y = [0,0]\n",
    "    x = [0,0,0,0,0,0,0]\n",
    "        \n",
    "    if state != 0:\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            # Get and scale inputs\n",
    "            x[i] = prox_horizontal[i] // sensor_scale\n",
    "            \n",
    "            # Compute outputs of neurons and set motor powers\n",
    "            y[0] = y[0] + x[i] * w_l[i]\n",
    "            y[1] = y[1] + x[i] * w_r[i]\n",
    "    \n",
    "    # Set motor powers\n",
    "    motor_left_target = y[0]\n",
    "    motor_right_target = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:43:53.331193Z",
     "start_time": "2021-09-29T14:43:51.594619Z"
    }
   },
   "outputs": [],
   "source": [
    "await tdmclient.notebook.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python vs. ASEBA Comparison\n",
    "\n",
    "Throughout the project you are going to have to choose between coding in python and coding in ASEBA. Both have their advantages and inconveniences. Here is the equivalent of the ASEBA code in python, **executed on your computer**. What differences do you find between the two? Which one would you prefer to keep ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "Have a look, with the help of a sowftare like PyCharm, at the file ann.py (src/ann.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "Add recurrent connection to have Thymio memorising the speed and continuing moving also without\n",
    "inputs from the sensors. Explore values below, equal and higher than one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "    # Thymio-II program: ANN for obstacle avoidance with memory\n",
    "    # Copyright 2017 by Francesco Mondada and Moti Ben-Ari\n",
    "    # CreativeCommons BY-SA 3.0\n",
    "\n",
    "    # This program implements obstacle avoidance using an ANN\n",
    "    # The inputs x1-7 are taken from the proximity sensors and scaled\n",
    "    # The inputs are multiplied by the weights \n",
    "    #   and used to set the motor powers\n",
    "    # The center button starts and stops the robot\n",
    "\n",
    "    # Weights of neuron inputs\n",
    "    var w_l[9] = [40,20,-20,-20,-40,30,-10,8,0]  # connection to left motor\n",
    "    var w_r[9] = [-40,-20,-20,20,40,-10,30,0,8]  # connection to right motor\n",
    "\n",
    "    # Neuron inputs and outputs\n",
    "    var x[9]\n",
    "    var y[2]\n",
    "\n",
    "    #iterations\n",
    "    var i\n",
    "\n",
    "    # Scale factors for sensors and constant factor\n",
    "    var sensor_scale   = 200\n",
    "    var constant_scale =  20\n",
    "\n",
    "    # State for start and stop\n",
    "    var state = 1\n",
    "\n",
    "    timer.period[0] = 100    # Milliseconds\n",
    "\n",
    "    # Toggle start and stop with center button\n",
    "    onevent button.center\n",
    "      when button.center == 0 do\n",
    "        if state == 0 then\n",
    "            state = 1\n",
    "        else\n",
    "          state = 0\n",
    "          motor.left.target  = 0\n",
    "          motor.right.target = 0\n",
    "        end\n",
    "      end\n",
    "\n",
    "    # Activiate neurons periodically\n",
    "    onevent timer0\n",
    "      # Do nothing if stopped\n",
    "      if state == 0 then return end\n",
    "\n",
    "      #memory\n",
    "      x[7] = y[0]/10\n",
    "      x[8] = y[1]/10\n",
    "\n",
    "      # Get and scale inputs\n",
    "      for i in 0:6 do\n",
    "        x[i] = prox.horizontal[i]/sensor_scale\n",
    "      end\n",
    "\n",
    "      # Compute outputs of neurons and set motor powers\n",
    "      y[0] = 0\n",
    "      y[1] = 0\n",
    "\n",
    "      for i in 0:8 do\n",
    "          y[0] += x[i]*w_l[i]\n",
    "          y[1] += x[i]*w_r[i]\n",
    "      end\n",
    "      motor.left.target  = y[0]\n",
    "      motor.right.target = y[1]\n",
    "\n",
    "</blockquote>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:44:32.617410Z",
     "start_time": "2021-09-29T14:44:30.053237Z"
    }
   },
   "outputs": [],
   "source": [
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:44:34.108289Z",
     "start_time": "2021-09-29T14:44:33.639295Z"
    }
   },
   "outputs": [],
   "source": [
    "%%run_python #%%transpile_to_aseba # Change to show the code generated in Aseba\n",
    "\n",
    "# This program implements obstacle avoidance using an ANN\n",
    "# The inputs x1-7 are taken from the proximity sensors and scaled\n",
    "# The inputs are multiplied by the weights \n",
    "#   and used to set the motor powers\n",
    "# The center button starts and stops the robot\n",
    "\n",
    "# State for start and stop, why is this instruction here? (hint: look at the aseba transpile code)\n",
    "state = 1\n",
    "y = [0,0] \n",
    "\n",
    "def see_nothing(sensor_array, threshold)\n",
    "    see_nothing = false\n",
    "    for in range(len(sensor_array))\n",
    "        if sensor_array[i] <= threshold\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "@onevent\n",
    "def button_center():\n",
    "    global state\n",
    "    if button_center == 1:\n",
    "        state = 1 if state==0 else 0\n",
    "\n",
    "@onevent\n",
    "def prox():\n",
    "    global prox_horizontal, motor_left_target, motor_right_target, button_center, state, y \n",
    "    #asymetric w_l[2] != w_r[2] so the robot choses one side if it arrives straight on the obstacle\n",
    "    w_l = [20,  10, -15, -10, -20, 6, 0]\n",
    "    w_r = [-20, -10, -10,  10,  20, 0, 6]\n",
    "\n",
    "    # Scale factors for sensors and constant factor\n",
    "    sensor_scale = 400\n",
    "    constant_scale = 20\n",
    "    \n",
    "    x = [0,0,0,0,0,0,0]\n",
    "    \n",
    "    if state != 0:\n",
    "        # Memory\n",
    "        x[5] = y[0]//10\n",
    "        x[6] = y[1]//10\n",
    "        \n",
    "        x[0]=0\n",
    "        x[4]=0\n",
    "        \n",
    "        for i in range(1,4):\n",
    "            # Get and scale inputs\n",
    "            x[i] = prox_horizontal[i] // sensor_scale\n",
    "        \n",
    "        y = [80,80]    \n",
    "        \n",
    "        for i in range(len(x)):    \n",
    "            # Compute outputs of neurons and set motor powers\n",
    "            y[0] = y[0] + x[i] * w_l[i]\n",
    "            y[1] = y[1] + x[i] * w_r[i]\n",
    "    else: \n",
    "        # In case we would like to stop the robot\n",
    "        y = [0,0] \n",
    "    \n",
    "    # Set motor powers\n",
    "    motor_left_target = y[0]\n",
    "    motor_right_target = y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hebbian Rule\n",
    "\n",
    "### On paper\n",
    "\n",
    "The artificial neural network below, with two linear neurons, two outputs and two inputs, has an\n",
    "activation which gives a good behavior of the system and should be reinforced. Apply the Hebb\n",
    "rule by detailing your choices and steps.\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/hebb_rule.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "\n",
    "The Hebb rule reinforces weights which have more influence on the good output. For the ANN above, since the activation is linear (identity), let's name the ANN input $x$ ($x_1=6$, $x_2=-12$) and the ANN output $y$ ($y_1=6$, $y_2=9$). The weight $w_{kj}$ from $x_k$ to $y_j$ is updated by\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\Delta w_{kj} = \\alpha y_k x_j\n",
    "\\end{eqnarray*}\n",
    "\n",
    "where $\\alpha$ is a scalar gain. If we choose $\\alpha=0.01$,\n",
    "\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\Delta w_{11} &=& 0.01 \\cdot 6 \\cdot 6 = 0.36 \\\\\n",
    "\\Delta w_{12} &=& 0.01 \\cdot 6 \\cdot 9 = 0.54 \\\\\n",
    "\\Delta w_{21} &=& -0.01 \\cdot 12 \\cdot 6 = -0.72 \\\\\n",
    "\\Delta w_{22} &=& -0.01 \\cdot 12 \\cdot 9 = -1.08\n",
    "\\end{eqnarray*}\n",
    "\n",
    "The new weights $w^+_{kj}=w_{kj}+\\Delta w_{kj}$ are\n",
    "\\begin{eqnarray*}\n",
    "w^+_{11} &=& 0.5 + 0.36 = 0.86 \\\\\n",
    "w^+_{12} &=& -0.5 + 0.54 = 0.04 \\\\\n",
    "w^+_{21} &=& -0.25 -0.72 = -0.97 \\\\\n",
    "w^+_{22} &=& -1 -1.08 = -2.08\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n",
    "</blockquote>\n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation \n",
    "\n",
    "Add Hebbian learning to the structure of ANN described in algorithm 2.1 that was provided earlier.\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/ANN_algorithm.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "Instead of making random movements and waiting for good situations to reinforce, you can present\n",
    "good situations to the network by placing the robot in an avoidance situation and pressing a button\n",
    "showing the right reaction, as illustrated in algorithm 2.2\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/ANN_algorithm_2.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "The application of the Hebbian rule in this situation follows algorithm 2.3. Test various learning\n",
    "rates.\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/ANN_hebb.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "    # Thymio-II program: Hebbian learning for obstacle avoidance\n",
    "    # Copyright 2017 by Francesco Mondada and Moti Ben-Ari\n",
    "    # CreativeCommons BY-SA 3.0\n",
    "\n",
    "    # Initially, the robot does not move or moves forward very slowly\n",
    "    # To train the robot to move forwards when an object is not\n",
    "    #   detected, touch the center button\n",
    "    # When the center / rear / left / right sensor detects your\n",
    "    #   finger, touch the back / front / right /left button\n",
    "    # Do the training one or more times\n",
    "    # The robot will update the ANN weights\n",
    "    #   and avoid an obstacle or move forwards if no obstacle\n",
    "\n",
    "    # Since all buttons are used, black paper or tape pushed\n",
    "    #   under a ground sensor starts and stops the robot\n",
    "    # Top leds indicate on or off\n",
    "\n",
    "    # Neuron inputs (7 IR sensors) and outputs\n",
    "    var x[7]\n",
    "    var y[2]\n",
    "\n",
    "    # Scale factors for sensors, outputs and motors\n",
    "    var sensor_scale   = 100\n",
    "    var output_scale   =  20\n",
    "    var motor_scale    =  15\n",
    "\n",
    "    # Constant input to move forwards\n",
    "    var constant_input =  25\n",
    "\n",
    "    # Threshold for start/stop with ground sensors\n",
    "    var start_stop_threshold = 300\n",
    "\n",
    "    # Left and right weights\n",
    "    var w_left[7]\n",
    "    var w_right[7]\n",
    "\n",
    "    # Learning rate\n",
    "    var alpha = 1\n",
    "\n",
    "    # Speed increment for each learning episode\n",
    "    var speed = 10\n",
    "\n",
    "    # The desired output for each button: +/-speed\n",
    "    var y_left\n",
    "    var y_right\n",
    "\n",
    "    # Loop index\n",
    "    var i\n",
    "\n",
    "    # Time period (millisecconds) to compute motor outputs from inputs\n",
    "    timer.period[0] = 100\n",
    "\n",
    "    # Start in off state and not moving\n",
    "    call leds.top(0,0,0)\n",
    "    motor.left.target  = 0\n",
    "    motor.right.target = 0\n",
    "\n",
    "    # Change weights according to Hebbian rule\n",
    "    sub change_weights\n",
    "        for i in 0:6 do\n",
    "            w_left[i]  = w_left[i]  + (alpha*y_left*x[i])  / output_scale\n",
    "            w_right[i] = w_right[i] + (alpha*y_right*x[i]) / output_scale\n",
    "        end\n",
    "\n",
    "    # For each button set y_left, y_right and change weights, center erase them\n",
    "    onevent button.center\n",
    "        for i in 0:6 do\n",
    "            w_left[i]  = 0\n",
    "            w_right[i] = 0\n",
    "        end\n",
    "\n",
    "    onevent button.left\n",
    "      y_left  = -speed\n",
    "      y_right = speed\n",
    "      callsub change_weights\n",
    "\n",
    "    onevent button.right\n",
    "      y_left  = speed\n",
    "      y_right = -speed\n",
    "      callsub change_weights\n",
    "\n",
    "    onevent button.forward\n",
    "      y_left  = speed\n",
    "      y_right = speed\n",
    "      callsub change_weights\n",
    "\n",
    "    onevent button.backward\n",
    "      y_left  = -speed\n",
    "      y_right = -speed\n",
    "      callsub change_weights\n",
    "\n",
    "    # Timer event\n",
    "    onevent timer0\n",
    "       # Read and scale inputs\n",
    "       for i in 0:6 do\n",
    "         x[i]=prox.horizontal[i]/sensor_scale\n",
    "       end\n",
    "\n",
    "       # Compute dot product of inputs and weights\n",
    "       y[0] = 0\n",
    "       y[1] = 0\n",
    "       for i in 0:6 do\n",
    "        y[0] = y[0] + x[i]*w_left[i]\n",
    "        y[1] = y[1] + x[i]*w_right[i]\n",
    "       end\n",
    "\n",
    "      # Scale and set motor powers\n",
    "      motor.left.target  = y[0] / motor_scale\n",
    "      motor.right.target = y[1] / motor_scale\n",
    "\n",
    "</blockquote>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:45:00.822697Z",
     "start_time": "2021-09-29T14:45:00.058264Z"
    }
   },
   "outputs": [],
   "source": [
    "%%run_python #%%transpile_to_aseba # Uncomment to show the code generated in Aseba\n",
    "\n",
    "# Initially, the robot does not move\n",
    "# To train the robot to move forwards when an object is not\n",
    "#   detected, touch the center button\n",
    "# When the center / rear / left / right sensor detects your\n",
    "#   finger, touch the back / front / right /left button\n",
    "# Do the training one or more times\n",
    "# The robot will update the ANN weights\n",
    "#   and avoid obstacles\n",
    "\n",
    "x = [0,0,0,0,0,0,0]\n",
    "y = [0,0]\n",
    "\n",
    "w_l = [0,0,0,0,0,0,0]\n",
    "w_r = [0,0,0,0,0,0,0]\n",
    "\n",
    "# Scale factors for sensors, outputs and motors\n",
    "sensor_scale = 100\n",
    "output_scale  = 20\n",
    "motor_scale  = 15\n",
    "    \n",
    "# Learning rate\n",
    "alpha = 1\n",
    "    \n",
    "# Speed increment for each learning episode\n",
    "speed = 10\n",
    "\n",
    "# The desired output for each button: +/-speed\n",
    "y_left = 0\n",
    "y_right = 0\n",
    "\n",
    "# Time period (millisecconds) to compute motor outputs from inputs\n",
    "timer_period[0] = 100\n",
    "\n",
    "leds_top = [0,0,0]\n",
    "motor_left_target  = 0\n",
    "motor_right_target = 0\n",
    "    \n",
    "def change_weights():\n",
    "    global w_l,w_r,alpha,y_left,y_right,x,output_scale\n",
    "    for i in range(7):\n",
    "        w_l[i]  = w_l[i]  + (alpha*y_left*x[i])  // output_scale\n",
    "        w_r[i] = w_r[i] + (alpha*y_right*x[i]) // output_scale    \n",
    "\n",
    "# For each button set y_left, y_right and change weights, center erase them\n",
    "@onevent\n",
    "def button_center():\n",
    "    global w_l, w_r\n",
    "    for i in range(7):\n",
    "        w_l[i]  = 0\n",
    "        w_r[i] = 0\n",
    "\n",
    "@onevent\n",
    "def button_left():\n",
    "    global y_left, y_right, speed\n",
    "    y_left  = -speed\n",
    "    y_right = speed\n",
    "    change_weights()\n",
    "\n",
    "@onevent\n",
    "def button_right():\n",
    "    global y_left, y_right, speed\n",
    "    y_left  = speed\n",
    "    y_right = -speed\n",
    "    change_weights()\n",
    "\n",
    "@onevent\n",
    "def button_forward():\n",
    "    global y_left, y_right, speed\n",
    "    y_right = speed\n",
    "    change_weights()\n",
    "\n",
    "@onevent\n",
    "def button_backward():\n",
    "    global y_left, y_right, speed\n",
    "    y_left  = -speed\n",
    "    y_right = -speed\n",
    "    change_weights()\n",
    "        \n",
    "@onevent\n",
    "def timer0():\n",
    "    global prox_horizontal, motor_left_target, motor_right_target, sensor_scale, x, y, w_l, w_r, motor_scale     \n",
    "        \n",
    "    for i in range(7):\n",
    "        # Get and scale inputs\n",
    "        x[i] = prox_horizontal[i] // sensor_scale\n",
    "    \n",
    "    # Compute dot product of inputs and weights\n",
    "    y = [0,0]    \n",
    "        \n",
    "    for i in range(7):    \n",
    "        y[0] = y[0] + x[i] * w_l[i]\n",
    "        y[1] = y[1] + x[i] * w_r[i]\n",
    "    \n",
    "    \n",
    "    # Set motor powers\n",
    "    motor_left_target = y[0] // motor_scale\n",
    "    motor_right_target = y[1] // motor_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "\n",
    "# Architectures\n",
    "\n",
    "Reactive behaviours allow to implement direct sensor-motor loops. These can include a memory\n",
    "effect, or have no memory at all. They can have a very simple structure or be composed by layers\n",
    "interacting with each other. We explore some simple reactive behaviours in the following exercise\n",
    "\n",
    "## Activity 5 : Finite State Machines\n",
    "\n",
    "Finite state machines allow us to describe a behaviour in a very abstract way using a state graph,\n",
    "helping to then program the system. \n",
    "\n",
    "\n",
    "Design a robot that moves on the G path given with this exercice with the following rule: \n",
    "\n",
    "The robot starts by following the line with the left ground sensor, turning clockwise, until it sees an obstacle.\n",
    "\n",
    "When this occurs, it changes behaviour and starts following the wall, until it sees a black transversal line with one of the ground sensors. \n",
    "\n",
    "When this occurs it moves forward until one of the ground sensors see white. \n",
    "\n",
    "When this occurs it starts following the line until it sees and obstacle, and so on. \n",
    "\n",
    "Draw a state diagram implementing this behaviour and then (only after!!!!) write the corresponding code for Thymio.\n",
    "\n",
    "The following files are provided in the zip folder to help :\n",
    "\n",
    "* ``path-transitions.pdf`` : Contains the G path in A3 format for the finite state machine exercise.\n",
    "\n",
    "![path-transitions](images/path-transitions.png)\n",
    "\n",
    "You can resolve the exercise either through ASEBA Studio or using the Python Bridge in order to do it via the Jupyter notebook. Note that the execution will likely be more efficient if you use ASEBA studio. \n",
    "\n",
    "\n",
    "<blockquote>\n",
    "    \n",
    "![FSM](images/FSM.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If *you tested the previous part of the correction*, beware that the previous code will still be loaded on the Thymio. To erase the code and begin in a clean state, you could turn your robot off and then on, or simply replace the previous code with this simple one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_python\n",
    "v = [32, 0, 32, 0, 32, 0, 32, 0]\n",
    "leds_circle = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then quit the tdmclient notebook method to avoid \"Node lock error\". The following line will unlock the robot, allowing to use a different approach here (ClientAsync)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:45:41.350782Z",
     "start_time": "2021-09-29T14:45:40.732547Z"
    }
   },
   "outputs": [],
   "source": [
    "await tdmclient.notebook.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "Please refer to the **Control your Thymio in Python** Jupyter tutorial that was provided to fully understand how to connect your Thymio using tdmclient. \n",
    "</blockquote>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:01.453189Z",
     "start_time": "2021-09-29T14:46:59.015915Z"
    }
   },
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n",
    "\n",
    "test_functions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "Just a quick reminder of the different variables that can be accessed through the node object\n",
    "</blockquote>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:04.070093Z",
     "start_time": "2021-09-29T14:47:03.829784Z"
    }
   },
   "outputs": [],
   "source": [
    "await node.wait_for_variables()\n",
    "node.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "For the line following behaviour, we are interested in the prox.ground.reflected variables which are going to be low when on a black surface (that tends to absord a big portion of the rays that come into contact with the surface) and high when on a white surface (which tends to reflect a high proportion of the incoming rays). You can check by running the following code. \n",
    "</blockquote>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:09.638063Z",
     "start_time": "2021-09-29T14:47:07.569497Z"
    }
   },
   "outputs": [],
   "source": [
    "async def print_sensor_values(sensor_id, print_range=10, delta_time=0.2):\n",
    "    \"\"\"\n",
    "    Print the sensor value sensor_id print_range times, every delta_time seconds\n",
    "    \"\"\"\n",
    "    await node.wait_for_variables({str(sensor_id)})\n",
    "    for i in range(print_range):\n",
    "        print(list(node[sensor_id]))\n",
    "        await client.sleep(delta_time)\n",
    "        \n",
    "await print_sensor_values('prox.ground.reflected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "However, for the wall following behaviour, we are interested in the `prox.horizontal` sensor values. Below we print them for 3 seconds. \n",
    "\n",
    "</blockquote>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:16.413928Z",
     "start_time": "2021-09-29T14:47:14.339535Z"
    }
   },
   "outputs": [],
   "source": [
    "await print_sensor_values('prox.horizontal', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "Now we can create the three functions that correspond to the states in the FSM showed before  :\n",
    "\n",
    "+ The line following behaviour \n",
    "\n",
    "+ The wall following behaviour\n",
    "\n",
    "+ The go straight behaviour\n",
    "\n",
    "<br>\n",
    "\n",
    "First we create a function to set the motor speeds which we test by setting the motor speeds to 500, waiting two seconds and then seting them to 0.\n",
    "\n",
    "</blockquote>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:24.153934Z",
     "start_time": "2021-09-29T14:47:21.869347Z"
    }
   },
   "outputs": [],
   "source": [
    "def motors(l_speed=500, r_speed=500, verbose=False):\n",
    "    \"\"\"\n",
    "    Sets the motor speeds of the Thymio \n",
    "    param l_speed: left motor speed\n",
    "    param r_speed: right motor speed\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "    # Printing the speeds if requested\n",
    "    if verbose:\n",
    "        print(\"\\t\\t Setting speed : \", l_speed, r_speed)\n",
    "    return {\n",
    "        \"motor.left.target\": [l_speed],\n",
    "        \"motor.right.target\": [r_speed],\n",
    "    }\n",
    "\n",
    "if test_functions:\n",
    "    await node.set_variables(motors(100, 100)) #test with lower speed value\n",
    "    await client.sleep(2)\n",
    "    await node.set_variables(motors(0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "\n",
    "Now we can move on to the behaviours themselves. \n",
    "\n",
    "***Go Straight***\n",
    "\n",
    "This go straight behaviour is defined as *`move forward until both ground sensors see some white`*.\n",
    "\n",
    "We create a test function for the ground sensors which returns True if both sensors see a value above the threshold. This is then used in the go_straight function that is meant to program the desired behaviour.\n",
    "\n",
    "\n",
    "</blockquote>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:26.329536Z",
     "start_time": "2021-09-29T14:47:26.317697Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_ground_white(white_threshold, verbose=False):\n",
    "    \"\"\"\n",
    "    Tests whether the two ground sensors have seen white\n",
    "    param white_threshold: threshold starting which it is considered that the sensor saw white\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "    if all([x>white_threshold for x in node['prox.ground.reflected']]):\n",
    "        if verbose: print(\"\\t\\t Saw white on the ground\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:28.754724Z",
     "start_time": "2021-09-29T14:47:28.309156Z"
    }
   },
   "outputs": [],
   "source": [
    "async def go_straight(motor_speed=100, white_threshold=500, verbose=False):\n",
    "    \"\"\"\n",
    "    Go Straight Behaviour of the FSM \n",
    "    param motor_speed: the Thymio's motor speed\n",
    "    param white_threshold: threshold starting which it is considered that the ground sensor saw white\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "    if verbose: print(\"Starting go straight behaviour\")\n",
    "    \n",
    "    # Move forward, i.e. set motor speeds\n",
    "    await node.set_variables(motors(motor_speed, motor_speed))\n",
    "    \n",
    "    # Until one of the ground sensors sees some white\n",
    "    saw_white = False\n",
    "    \n",
    "    await node.wait_for_variables({\"prox.ground.reflected\"})\n",
    "    \n",
    "    while not saw_white:\n",
    "        if test_ground_white(white_threshold, verbose=verbose):\n",
    "            saw_white=True\n",
    "            if verbose: print(\"\\t Saw white on the ground, exiting go straight behaviour\")\n",
    "        await client.sleep(0.2) #otherwise, variables would not be updated\n",
    "    return \n",
    "\n",
    "if test_functions:\n",
    "    await go_straight(100,500,True)\n",
    "    await node.set_variables(motors(0, 0))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "\n",
    "***Line Following***\n",
    "\n",
    "The line following behaviour is defined as *`follow the line with the left ground sensor, turning clockwise until it sees an obstacle`*. \n",
    "\n",
    "Similarly, we create a test function for the proximity sensors at the front of the Thymio to return True if a wall has been sensed in front of the robot. We then use this function in the line following behaviour.\n",
    "\n",
    "</blockquote>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:31.873946Z",
     "start_time": "2021-09-29T14:47:31.845829Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_saw_wall(wall_threshold, verbose=False):\n",
    "    \"\"\"\n",
    "    Tests whether one of the proximity sensors saw a wall\n",
    "    param wall_threshold: threshold starting which it is considered that the sensor saw a wall\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "    if any([x>wall_threshold for x in node['prox.horizontal'][:-2]]):\n",
    "        if verbose: print(\"\\t\\t Saw a wall\")\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:47:35.764725Z",
     "start_time": "2021-09-29T14:47:32.536826Z"
    }
   },
   "outputs": [],
   "source": [
    "async def line_following(motor_speed=30, wall_threshold=1000, white_threshold=500, verbose=False):\n",
    "    \"\"\"\n",
    "    Line following behaviour of the FSM\n",
    "    param motor_speed: the Thymio's motor speed\n",
    "    param wall_threshold: threshold starting which it is considered that the sensor saw a wall\n",
    "    param white_threshold: threshold starting which it is considered that the ground sensor saw white\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose: print(\"Starting line following behaviour\")\n",
    "    saw_wall = False\n",
    "    \n",
    "    if verbose: print(\"\\t Moving forward\")\n",
    "       \n",
    "    prev_state=\"forward\"\n",
    "    await node.set_variables(motors(motor_speed, motor_speed))\n",
    "    \n",
    "    while not saw_wall:\n",
    "        if test_ground_white(white_threshold):\n",
    "            if prev_state==\"forward\": \n",
    "                if verbose: print(\"\\t Saw white, turning clockwise\")\n",
    "                await node.set_variables(motors(motor_speed, -motor_speed))\n",
    "                prev_state=\"turning\"\n",
    "        else:\n",
    "            if prev_state==\"turning\": \n",
    "                if verbose: print(\"\\t Moving forward\")\n",
    "                await node.set_variables(motors(motor_speed, motor_speed))\n",
    "                prev_state=\"forward\"\n",
    "\n",
    "        if test_saw_wall(wall_threshold,verbose): saw_wall = True\n",
    "        await client.sleep(0.1) #otherwise, variables would not be updated\n",
    "    return \n",
    "\n",
    "if test_functions:\n",
    "    await line_following(verbose=True, motor_speed=20)\n",
    "    await node.set_variables(motors(0, 0))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "\n",
    "***Wall Following***\n",
    "\n",
    "The wall following behaviour is defined as *`follow the wall, until it sees a black transversal\n",
    "line with a ground sensor`*. \n",
    "\n",
    "\n",
    "This is very similar to the line following behaviour but\n",
    "\n",
    "- instead of following based on the ground sensors, we use the horizontal proximity sensors. \n",
    "\n",
    "- instead of stopping based on the presence of a wall, we stop based on the ground sensor values as soon as one sees black. \n",
    "\n",
    "We start by defining a function for our stopping critereon.\n",
    "\n",
    "\n",
    "\n",
    "</blockquote>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:49:39.751023Z",
     "start_time": "2021-09-29T14:49:26.099833Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_saw_black(white_threshold, verbose=True):\n",
    "    \"\"\"\n",
    "    Line following behaviour of the FSM\n",
    "    param white_threshold: threshold starting which it is considered that the ground sensor saw white\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "    \n",
    "    if any([x<=white_threshold for x in node['prox.ground.reflected']]):\n",
    "        if verbose: print(\"\\t\\t Both ground sensors saw black\")\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "async def wall_following(motor_speed=20, wall_threshold=500, white_threshold=200, verbose=False):\n",
    "    \"\"\"\n",
    "    Wall following behaviour of the FSM\n",
    "    param motor_speed: the Thymio's motor speed\n",
    "    param wall_threshold: threshold starting which it is considered that the sensor saw a wall\n",
    "    param white_threshold: threshold starting which it is considered that the ground sensor saw white\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose: print(\"Starting wall following behaviour\")\n",
    "    saw_black = False\n",
    "    \n",
    "    if verbose: print(\"\\t Moving forward\")\n",
    "    await node.set_variables(motors(motor_speed, motor_speed))\n",
    "           \n",
    "    prev_state=\"forward\"\n",
    "    \n",
    "    while not saw_black:\n",
    "        \n",
    "        if test_saw_wall(wall_threshold, verbose=False):\n",
    "            if prev_state==\"forward\": \n",
    "                if verbose: print(\"\\tSaw wall, turning clockwise\")\n",
    "                await node.set_variables(motors(motor_speed, -motor_speed))\n",
    "                prev_state=\"turning\"\n",
    "        \n",
    "        else:\n",
    "            if prev_state==\"turning\": \n",
    "                if verbose: print(\"\\t Moving forward\")\n",
    "                await node.set_variables(motors(motor_speed, motor_speed))\n",
    "                prev_state=\"forward\"\n",
    "\n",
    "        if test_saw_black(white_threshold, verbose): saw_black = True\n",
    "        await client.sleep(0.1) #otherwise, variables would not be updated\n",
    "    return \n",
    "\n",
    "if test_functions:\n",
    "    await wall_following(verbose=True)\n",
    "    await node.set_variables(motors(0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "\n",
    "***The FSM***\n",
    "\n",
    "Now we are going to implement the whole FSM. Note you are going to have to stop the execution of the cell manually. \n",
    "\n",
    "</blockquote>\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:49:43.941631Z",
     "start_time": "2021-09-29T14:49:43.923986Z"
    }
   },
   "outputs": [],
   "source": [
    "async def g_path_FSM(speed, verbose=True):\n",
    "    while True:\n",
    "        # Step 1: line following\n",
    "        await line_following(speed, verbose=verbose)\n",
    "        \n",
    "        # Step 2: wall following\n",
    "        await wall_following(speed, verbose=verbose)\n",
    "        \n",
    "        # Step 3: \n",
    "        await go_straight(speed, verbose=verbose)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #2980B9 ;\">\n",
    "<blockquote>\n",
    "\n",
    "\n",
    "***The FSM***\n",
    "\n",
    "Now we can finally test it :)\n",
    "\n",
    "</blockquote>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:50:07.730987Z",
     "start_time": "2021-09-29T14:49:45.028269Z"
    }
   },
   "outputs": [],
   "source": [
    "if test_functions:\n",
    "    await g_path_FSM(50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T14:50:11.523836Z",
     "start_time": "2021-09-29T14:50:11.378117Z"
    }
   },
   "outputs": [],
   "source": [
    "await node.set_variables(motors(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
