{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "The filtering was done using a Kalman Filter. We designed it to use the position and the angle given by the camera as measurement and the speed of the robot, given by the sensors of the wheels, as prediction. For simplicity of use, we decided to create a Kalman_Filter class, so we would have less arguments to give to each functions. However, this class needs to have access to the class Vision and to be given the speed of the robot to work properly.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T10:16:20.177388Z",
     "start_time": "2021-12-12T10:16:20.146175Z"
    }
   },
   "source": [
    "### Equations\n",
    "The Kalman filter merge together a prediction of the future state of the system with a measure of these states to be more precise. The prediction is govern by the system equations. In this section, we are going to describe the equations used in the model and the ones used to implement the merging part of the filter. \n",
    "First, we need to convert the informations we get from the sensors to something we can use:\n",
    "$v = (v_r + v_l)/2$. This is the translational speed and $w = (v_r - v_l)/b$, which is the rotationnal speed. $v_r$ is the speed of the right wheel, $v_l$ the left one and $b$ is the width of the robot, wheel to wheel. These speed are given in thymio units, so we need to convert them in mm or in pixels to use them with the other values. For w, we just want to change it to mm because b is given in mm and for v, the position are given in pixels unit so we have to convert it first to mm and then to pixels.\n",
    "From $w$, we can compute the variation of angle that the robot does when it moves: $\\alpha = w * \\delta t$.\n",
    "We have three states for our filter, which are $x$, $y$, and $\\theta$, respectively the position on the x and y axis and the orientation from the x axis. The state vector is called $\\rho$ and the vector of input ($[v ; w]$) is called u for simplication of writing. Therefore, the model equation is the following: $\\rho_{k+1} = A * \\rho_k + B * u_k$. We now need to determine the matrixes A and B. For this, we have to know how the system evolve with each steps. For x, we can find that $x_{k+1} = x_k + v * \\cos(\\alpha + \\theta) * \\delta t$ and for y: $y_{k+1} = y_k + v *\\sin(\\alpha + \\theta)* \\delta t$. Finally, for $\\theta$, we have $\\theta_{k+1} = \\theta_k + w *\\delta t$. From this we can find that the matrix A is  \\begin{bmatrix} 1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix} and the B matrix  \\begin{bmatrix} \\cos(\\alpha + \\theta) * \\delta t & 0\\\\ \\sin(\\alpha + \\theta) * \\delta t & 0 \\\\ 0 & \\delta t \\end{bmatrix}\n",
    "We now have a model for the predictive part of our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T14:55:49.833569Z",
     "start_time": "2021-12-12T14:55:49.802353Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pos = [50, 60, np.pi/4]\n",
    "speed = [200, 200]\n",
    "b = 100\n",
    "THYMIO_SPEED_2_MM = 0.435\n",
    "mm2px = 0.5\n",
    "time = 0.1\n",
    "P_est = 1000 * np.ones(3)\n",
    "Q = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 0.1]])\n",
    "\n",
    "v = mm2px * THYMIO_SPEED_2_MM *(speed[0] + speed[1])/2\n",
    "w = THYMIO_SPEED_2_MM *(speed[0] - speed[1])/b\n",
    "alpha = w * time\n",
    "rho_est = pos\n",
    "u = np.array([v, w])\n",
    "\n",
    "A = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "B = np.array([[time * np.cos(alpha + rho_est[2]), 0], [time * np.sin(alpha + rho_est[2]), 0], [0, time]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start the real algorithm of our filter: we start by computing the estimation of our states $\\rho_{est\\text{ }a\\text{ }priori}$ with our model equation. We can then compute the Covariance matrix P: $P_{est \\text{ }a\\text{ }priori} = A * P_{est} * A^T + Q$ where Q is the error covariance matrix for the estimation and $Q =\\begin{bmatrix} 1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0.1\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T14:55:50.519989Z",
     "start_time": "2021-12-12T14:55:50.504365Z"
    }
   },
   "outputs": [],
   "source": [
    "rho_est_a_priori = np.dot(A, rho_est) + np.dot(B, u)\n",
    "P_est_a_priori = np.dot(A, np.dot(P_est, A.T)) + Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we need to see if the camera gives us measurement or not. This sadly is only possible with the camera connected so for this demo we are setting a variable acting like the function robot_detected() from our vision module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera connected\n",
    "If the camera is detected, we set the measurement as the values retourned by the camera, $pos_x$, $pos_y$ and $\\theta$. This will be our measurement vector $y$. We also compute the covariance matrix for measurement, $S = C * P_{est \\text{ }a\\text{ }priori} * C^T + R$, where $C$ is the matrix linking measurements and states and $R$ is the error covariance matrix for the measurement. Finally, we compute the Kalman gain, which is the gain for the measurements $K = P_{est \\text{ }a\\text{ }priori} * C^T * S^{-1}$.\n",
    "We chose to have a small R compared to Q because we want to put much more weight on the camera measurements, the speed sensors being less precise. That way, when our camera is active the kalman filter will output almost the same position as the position given by the camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T14:55:51.438358Z",
     "start_time": "2021-12-12T14:55:51.407143Z"
    }
   },
   "outputs": [],
   "source": [
    "C = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "R = np.array([[0.1, 0, 0], [0, 0.1, 0], [0, 0, 0.01]])\n",
    "robot_detected = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera not connected\n",
    "If the camera is not connected we set the kalman gain to 0 and therefore we do not compute $S$. For $y$, we simply set it to the last known position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T14:55:52.156131Z",
     "start_time": "2021-12-12T14:55:52.140504Z"
    }
   },
   "outputs": [],
   "source": [
    "if robot_detected:   \n",
    "    y = pos\n",
    "    S = np.dot(C, np.dot(P_est_a_priori, C.T)) + R\n",
    "    K = np.dot(P_est_a_priori, np.dot(C.T, np.linalg.inv(S)))\n",
    "else:\n",
    "    K = 0\n",
    "    y = rho_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the innovation (the difference between the measured positions and the estimated positions) $i = y - C * \\rho_{est\\text{ }a\\text{ }priori}$. We can now compute the new estimation of the position $\\rho_{est} = \\rho_{est\\text{ }a\\text{ }priori} + K * i$ and the new covariance matrix $P_{est} = (I - K * C) * P_{est\\text{ }a\\text{ }priori}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T14:55:53.243962Z",
     "start_time": "2021-12-12T14:55:53.228335Z"
    }
   },
   "outputs": [],
   "source": [
    "i = y - np.dot(C, rho_est_a_priori)\n",
    "rho_est = rho_est_a_priori + np.dot(K, i)\n",
    "P_est = np.dot((np.identity(3) - np.dot(K, C)), P_est_a_priori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the effect of the filter, we can print the value of $\\rho_{est}$ and the position given by the camera. Of course, with this example being a static one, the position given by the estimate won't be the same as the one seen by the camera, because the camera gives us the last position and the estimate the next position, but it allows us to see the effect of the filter, for example by changing the speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T14:59:46.695099Z",
     "start_time": "2021-12-12T14:59:46.657369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50.2330281  60.2330281   0.73879767] position estimée\n",
      "[50, 60, 0.7853981633974483] position given by camera\n",
      "[[1001.  1000.  1000. ]\n",
      " [1000.  1001.  1000. ]\n",
      " [1000.  1000.  1000.1]]\n"
     ]
    }
   ],
   "source": [
    "print(rho_est, \"position estimée\")\n",
    "print(pos, \"position given by camera\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}